# CUDA 优化笔记

## 1. 内核优化工作流程与三大瓶颈

CUDA 内核优化是一个迭代的过程，旨在识别并解决性能瓶颈。

### 1.1 内核优化工作流程

* **找到限制器 (Find Limiter)**：通过分析器（如 Nsight Compute）识别当前内核的瓶颈是内存受限、指令受限还是延迟受限。
* **内存受限 (Memory Bound)**：
    * **判断**：与峰值内存带宽（GB/s）进行比较。如果有效内存吞吐量远低于峰值，则可能是内存受限。
    * **优化**：进行内存优化。
* **指令受限 (Instruction Bound)**：
    * **判断**：与峰值指令吞吐量（Inst/s）进行比较。
    * **优化**：进行指令优化。
* **延迟受限 (Latency Bound)**：
    * **判断**：当等待时没有足够的 Warp 可切换，表明计算单元因等待而空闲。
    * **优化**：进行配置优化。
* **完成！** 当达到理想性能时。

### 1.2 三大瓶颈

CUDA 内核性能的限制因素主要有三种：

1.  **内存带宽限制 (Memory Bandwidth Bound)**：
    * 指受限于内存子系统（如 GDDR、L2/TEX/L1 缓存、共享内存）的数据传输速度。
    * 表现为有效内存吞吐量远低于硬件峰值。
2.  **指令吞吐量限制 (Instruction Throughput Bound)**：
    * 指受限于 GPU 计算单元的指令执行速度，例如单精度/双精度浮点运算、加载/存储 (LDST) 或特殊功能单元 (SFU) 的吞吐量。
    * 表现为有效指令吞吐量远低于硬件峰值。
3.  **延迟限制 (Latency Bound)**：
    * 指由于缺乏足够的并行工作（活跃的 Warp），导致计算单元在等待数据或指令时空闲。
    * GPU 通过切换不同 Warp 来隐藏延迟，但如果活跃 Warp 数量不足，延迟就无法被完全隐藏。

### 1.3 如何找到瓶颈？—— 分析器！

NVIDIA Nsight Compute 是一个强大的性能分析工具，可以帮助开发者识别 CUDA 内核的瓶颈，并提供详细的性能指标。

* **Nsight Compute CLI (Command Line Interface)**：用于非交互式性能收集和分析。
* **Nsight Compute UI (User Interface)**：提供图形化界面，用于交互式分析和可视化性能数据。

**使用 Nsight Compute 识别瓶颈的基本步骤：**

1.  **收集数据**：运行 `nv-nsight-cu-cli` 命令收集内核的性能数据。
    ```bash
    nv-nsight-cu-cli --metrics all --set full_pc app_name args
    ```
2.  **分析报告**：打开生成的报告，关注关键指标，如：
    * **GPU Utilization (GPU 利用率)**：整体 GPU 繁忙程度。
    * **Memory Throughput (内存吞吐量)**：实际内存带宽利用率。
    * **Instruction Throughput (指令吞吐量)**：实际指令执行速率。
    * **Occupancy (占用率)**：SM 上活跃 Warp 的比例。
    * **Cache Hit Rates (缓存命中率)**：L1/L2/Texture 缓存的有效性。

## 2. 内存优化

如果代码是内存密集型的，且有效内存吞吐量远低于峰值，则需要进行内存优化。

### 2.1 目的与主要技术

* **目的**：只访问绝对必要的数据，并以最高效的方式访问。
* **主要技术**：
    * 减少冗余内存访问。
    * 利用片上缓存：纹理内存 (TEX)/只读内存、共享内存、常量内存。
    * 重新排列指令以增加数据局部性 (这里PDF原文有些含糊，更准确的说法是重新排列数据和访问模式)。

### 2.2 具体优化策略

#### 2.2.1 合并全局内存访问 (Coalesced Global Memory Access)

* **原理**：GPU 的全局内存访问是以特定粒度（通常是 32B、64B 或 128B）进行的。当一个 Warp 中的 32 个线程以连续的、对齐的方式访问全局内存时，这些访问可以被合并（Coalesced）成一个或少数几个内存事务，从而最大限度地利用内存带宽。
* **低效情况**：如果线程访问分散或不连续的内存位置，会产生更多的内存事务，导致效率低下。
    * 例如：`A[threadIdx.x * stride]` 会导致非常分散的访问。
* **优化建议**：
    * **对齐数据**：确保数据在内存中对齐，以匹配内存事务的粒度。
    * **合并访问模式**：设计内核，使 Warp 中的线程访问连续的内存地址。
        * 一维数组：`array[blockIdx.x * blockDim.x + threadIdx.x]`
        * 二维数组：`array[row * width + col]`，确保 `col` 变化时是连续的。

**示例：合并访问**

```c++
// 合并访问示例
__global__ void add_vectors_coalesced(float* a, float* b, float* c, int N) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < N) {
        c[idx] = a[idx] + b[idx]; // 理想情况下，warp内的所有线程访问连续地址
    }
}

// 分散访问示例 (避免)
__global__ void add_vectors_scattered(float* a, float* b, float* c, int N) {
    int idx = blockIdx.x + threadIdx.x * gridDim.x; // threadIdx.x 步长过大
    if (idx < N) {
        c[idx] = a[idx] + b[idx];
    }
}
```

#### 2.2.2 内存对齐 (Memory Alignment)

* **原理**：CUDA 全局内存事务通常是 32、64 或 128 字节。如果内存访问的起始地址不是这些粒度的倍数，或者数据跨越了事务边界，GPU 可能需要额外的事务来获取所需数据，导致带宽浪费。
* **示例**：一个 128 字节的事务如果从非 128 字节对齐的地址开始，可能会跨越两个 128 字节的块，从而需要两次内存事务。

#### 2.2.3 优化结构体：AoS vs. SoA (Array of Structures vs. Structure of Arrays)

* **AoS (Array of Structures)**：
    ```c++
    struct Point {
        float x, y, z;
    };
    Point points[N]; // points[0] = {x0, y0, z0}, points[1] = {x1, y1, z1}, ...
    ```
    * **优点**：将相关数据打包在一起，利于C++的面向对象编程。
    * **缺点**：在 GPU 上可能效率低下，因为如果线程只访问结构体的一部分成员（例如只访问 `x` 坐标），会导致不必要的内存加载，且访问 `x` 坐标时在内存中不连续。
* **SoA (Structure of Arrays)**：
    ```c++
    struct Point_SoA {
        float x[N];
        float y[N];
        float z[N];
    };
    Point_SoA points; // points.x = {x0, x1, ...}, points.y = {y0, y1, ...}, ...
    ```
    * **优点**：将相同类型的数据打包在一起，使得线程对同一类型数据进行操作时可以实现连续的内存访问，从而提高合并访问的效率和数据局部性。
    * **缺点**：对于需要同时访问结构体所有成员的操作可能不太直观，代码可读性可能略有下降。

**选择**：在 GPU 上，SoA 通常比 AoS 更高效，尤其是在 SIMT 架构下，线程通常对相同类型的数据执行相同的操作。

#### 2.2.4 使用固定大小数组代替动态分配数组

* **固定大小数组 (Static Array)**：
    * **优点**：编译时已知大小，编译器可以进行更好的优化（如内存布局、寄存器分配）。通常存储在栈上（对于线程局部变量）或常量内存中，访问速度快。
    * **缺点**：大小固定，不灵活。
* **动态分配数组 (Dynamic Array)**：
    * **优点**：运行时大小可变，灵活性高。
    * **缺点**：通常存储在全局内存（堆）中，访问速度慢，且需要额外的内存管理开销（`cudaMalloc`，`cudaFree`）。

**建议**：如果数组大小已知且不大，优先使用固定大小数组。

#### 2.2.5 在全局内存中填充数据以填充内存事务 (Padding Data in Global Memory)

* **原理**：为了充分利用内存事务的带宽，可以将数据结构进行填充（Padding），使其总大小成为内存事务粒度（如 128 字节）的倍数。
* **示例**：
    ```c++
    struct MyData {
        float a;
        float b;
        char padding[120]; // 填充以使总大小为128字节 (4+4+120=128)
    };
    ```
* **重要性**：对于频繁访问的小型数据结构尤为重要，可以避免带宽浪费。

#### 2.2.6 避免共享内存银行冲突 (Shared Memory Bank Conflicts)

* **原理**：共享内存被划分为独立的内存银行（通常 32 个）。当一个 Warp 中的多个线程在同一时钟周期内尝试访问同一银行的不同地址时，会发生银行冲突。冲突会导致访问序列化，从而降低性能。
* **无冲突情况**：
    * 如果每个线程访问不同银行的地址。
    * 如果所有线程访问同一共享内存地址（广播，无冲突）。
* **避免方法**：
    * **数据重排**：通过添加填充或调整访问模式，确保线程访问映射到不同的银行。
    * **数学计算**：在计算共享内存索引时，可以加入偏移量或使用模运算来分散访问。
* **示例**：
    ```c++
    __shared__ float s_data[128]; // 假设128个float，每个float 4字节，共有32个银行（128/4 = 32）
                                // 如果 bank_size = 4B，那么 s_data[0] 属于 bank 0，s_data[1] 属于 bank 1 ... s_data[31] 属于 bank 31，s_data[32] 属于 bank 0。

    // 避免银行冲突的示例 (如果idx每次都映射到不同银行)
    // 假设 threadIdx.x 依次是 0, 1, 2, ..., 31
    // s_data[0], s_data[1], ..., s_data[31] 对应不同的银行，无冲突
    int idx = threadIdx.x;
    s_data[idx] = global_data[idx];

    // 银行冲突的示例 (如果 bank_size = 4B)
    // 所有线程尝试访问 bank 0 的不同位置
    // 例如：thread 0 访问 s_data[0]，thread 1 访问 s_data[32]，thread 2 访问 s_data[64]
    // 它们都映射到 bank 0，会发生冲突
    // int idx_conflicting = threadIdx.x * 32;
    // s_data[idx_conflicting] = global_data[idx_conflicting];
    ```
    **解决冲突的一种常见方法：添加一个填充维度**
    ```c++
    // 假设 bank_size = 4B，数据类型为 float
    // 为避免银行冲突，在共享内存数组的维度上添加一个填充因子
    // 例如，如果共享内存数组的大小为 blockDim.x，可以将其声明为 blockDim.x + PADDING_SIZE
    // 使得 blockDim.x % BANK_COUNT != 0
    __shared__ float s_data_padded[128 + 1]; // +1 是为了稍微调整对齐，通常通过2D共享内存或显式填充实现
    int idx_padded = threadIdx.x + threadIdx.x / (BANK_COUNT); // 简单示例，实际情况需要更复杂的映射
    // 或者更常见的做法是使用2D共享内存，并在第二个维度上添加填充
    __shared__ float matrix_tile[TILE_DIM][TILE_DIM + 1]; // +1 避免TILE_DIM是BANK_COUNT倍数时的冲突

    // 访问：matrix_tile[row][col]
    ```
    银行冲突是一个复杂的话题，具体的避免策略取决于访问模式和数据结构。

### 2.3 利用片上缓存

#### 2.3.1 共享内存 (Shared Memory)

* **特点**：
    * 片上存储（on-chip），比全局内存延迟低（快 10-100 倍），带宽更高。
    * 在同一线程块内的线程之间共享数据。
    * 需要程序员显式管理 (`__shared__` 关键字)。
* **声明**：`__shared__ int data[1024];`
* **用途**：
    * **减少全局内存访问**：将频繁访问的数据从全局内存加载到共享内存一次，然后由块内的所有线程多次使用。
    * **线程间通信**：在同一块内的线程之间传递数据。
    * **高效数据重用**：如矩阵乘法中的分块算法。
* **同步**：`__syncthreads()` 用于确保块内所有线程都完成了对共享内存的读写操作，以避免数据竞争。

#### 2.3.2 常量内存 (Constant Memory)

* **特点**：
    * 全局内存的一个缓存区，用于存储内核执行期间不会改变的常量数据。
    * 全局可读：对所有线程和所有块可见。
    * **专用缓存**：如果一个 Warp 中的所有线程都访问相同的常量地址，则访问速度非常快（与寄存器访问相似）。
    * 容量有限（通常几十 KB）。
* **声明**：`__constant__ float my_const_array[100];`
* **数据传输**：必须通过 `cudaMemcpyToSymbol` 从主机复制到设备。
* **性能影响**：
    * **合并访问**：如果 Warp 内所有线程读取相同的常量地址，访问是并行的且高效。
    * **分散访问**：如果 Warp 内线程读取不同的常量地址，性能会下降，因为它可能会退化为全局内存访问。
* **使用场景**：查找表、配置参数、滤波器系数等。

#### 2.3.3 纹理内存 (Texture Memory) 和 只读缓存 (Read-Only Cache)

* **纹理内存 (Texture Memory)**：
    * 专门为 2D 和 3D 空间局部性访问优化，例如图像处理中的邻近像素访问。
    * 内置纹理缓存，通常比全局内存提供更高的带宽。
    * 支持地址模式（如边界处理，插值）。
    * **适用场景**：图像处理、信号处理、物理模拟中的查找表。
* **只读缓存 (Read-Only Cache)**：
    * 所有全局内存读取都可以选择通过只读缓存。
    * 对于只读数据，它可以提供额外的缓存层，提高数据重用时的效率。
    * 使用 `__ldg()` 内在函数可以强制通过只读缓存加载数据（需要 Compute Capability 3.5 或更高）。

## 3. 指令优化

如果代码是指令密集型的，且有效指令吞吐量远低于峰值，则需要进行指令优化。

### 3.1 目的与主要技术

* **目的**：减少指令数量和复杂度。
* **主要技术**：
    1.  减少分支和 Warp 发散。
    2.  算术指令优化。
    3.  减少寄存器使用。

### 3.2 具体优化策略

#### 3.2.1 减少分支和 Warp 发散 (Branching and Warp Divergence)

* **Warp 发散**：当一个 Warp 中的线程遇到条件分支 (`if/else`、`switch`)，并采取不同的执行路径时，就会发生 Warp 发散。
* **影响**：GPU 的 SIMT (Single Instruction Multiple Multiple Thread) 架构意味着一个 Warp 中的所有线程应该执行相同的指令。如果发生发散，硬件会依次执行每个分支，导致串行化，降低并行度，从而降低有效吞吐量。
* **避免方法**：
    * **无分支代码**：尽可能使用无分支的算法。
    * **条件赋值**：对于简单的分支，可以使用三元运算符 (`? :`) 或位运算替代 `if/else`。
        ```c++
        // 避免 if/else 导致的warp发散
        // 原始代码:
        // if (condition) { result = val1; } else { result = val2; }
        // 优化后 (条件赋值):
        float result = condition ? val1 : val2;

        // 位运算替代 (例如，计算绝对值)
        // 原始代码:
        // if (x < 0) { x = -x; }
        // 优化后 (使用位运算):
        // int sign_mask = x >> 31; // 获取符号位
        // x = (x ^ sign_mask) - sign_mask; // 异或并减去，实现绝对值
        ```
    * **数据并行化**：设计算法时，尽量将数据处理并行化，减少线程之间的依赖和条件判断。

#### 3.2.2 算术指令优化

* **避免双精度 (Double Precision)**：
    * 双精度浮点运算 (`double`) 通常比单精度浮点运算 (`float`) 慢得多，并且消耗更多资源（如 ALU 单元）。
    * **建议**：除非应用确实需要极高的精度，否则应优先使用单精度浮点数。
* **使用内在函数 (Intrinsic Functions)**：
    * CUDA 提供了许多内在函数 (`__` 前缀)，它们可以直接映射到 GPU 硬件指令，通常比标准 C/C++ 函数更快，因为它们绕过了通用编译器的优化阶段，直接生成硬件指令。
    * **示例**：
        * `__fadd_rn(x, y)`：单精度浮点加法，round-to-nearest。
        * `__mul24(x, y)`：24 位整数乘法，通常用于地址计算。
        * `__sinf(x)`，`__cosf(x)`，`__expf(x)` 等：比标准库的 `sinf()`, `cosf()`, `expf()` 更快，但精度可能略低。

#### 3.2.3 减少寄存器使用 (Reduce Register Usage)

* **寄存器溢出 (Register Spilling)**：
    * 每个线程都有一定数量的寄存器可用。如果一个内核使用的寄存器过多，就会发生寄存器溢出。
    * 溢出意味着一些寄存器数据被迫存储到本地内存（Local Memory）中。
    * 本地内存存储在全局内存中，访问速度比寄存器慢得多，会导致性能显著下降。
* **影响**：
    * **降低占用率 (Occupancy)**：高寄存器使用量会减少每个 SM 可并发执行的 Warp 数量。
    * **增加全局内存访问**：因为寄存器数据被溢出到本地内存，需要更多的全局内存读写。
    * **增加延迟**：本地内存访问的延迟较高。
* **优化建议**：
    * **减少变量数量**：尽可能复用变量，避免声明不必要的临时变量。
    * **将数据存储在共享内存中**：对于块内共享的数据，将其放入共享内存可以减少每个线程的寄存器需求。
    * **编译器选项**：使用 `-maxrregcount` 编译选项可以限制每个线程的寄存器使用量，但这可能会导致更多的寄存器溢出。最佳实践是让编译器自行优化，并通过性能分析器检查是否发生溢出。

## 4. 延迟优化

如果代码是延迟密集型的，并且有足够的并行性可用，则需要进行延迟优化。

### 4.1 目的与主要技术

* **目的**：最大化占用率（Occupancy），以隐藏内存和指令延迟。
* **主要技术**：
    1.  调整启动配置（Launch Configuration）。
    2.  优化寄存器使用（如前所述，减少寄存器使用可以提高占用率）。
    3.  优化共享内存使用（共享内存的大小也会影响占用率）。

### 4.2 具体优化策略

#### 4.2.1 调整启动配置 (Launch Configuration)

* **线程块的维度 (`blockDim.x`, `blockDim.y`, `blockDim.z`)**：
    * 通常，线程块的大小应为 Warp 大小（32）的倍数，例如 64、128、256、512 或 1024。
    * **优点**：较大的块可以提供更多的并行性，有助于实现高占用率。
    * **缺点**：较大的块会消耗更多的共享内存和寄存器，可能限制 SM 上并发块的数量。
    * **选择**：尝试不同的块大小，并通过分析器找到最佳平衡点。
* **网格的维度 (`gridDim.x`, `gridDim.y`, `gridDim.z`)**：
    * 网格中的块数通常取决于要处理的数据量。
    * **原则**：网格应该足够大，以充分利用所有 SM。通常建议网格中的块总数至少是 SM 数量的几倍，以确保所有 SM 都有足够的工作。
    * 对于简单的 N 个元素的向量操作，`gridDim.x = (N + blockDim.x - 1) / blockDim.x`。

#### 4.2.2 GPU 体系结构回顾 (Review of GPU Architecture)

* **SM (Streaming Multiprocessor)**：GPU 的核心计算单元。每个 SM 包含多个 CUDA 核、共享内存和寄存器文件。
* **线程块 (Thread Block)**：一个线程块在一个 SM 上执行。
* **并发执行**：一个 SM 可以并发执行多个线程块，前提是资源（寄存器、共享内存）允许。
* **Warp 调度**：SM 内的线程按 Warp（通常 32 个线程）调度和执行。

#### 4.2.3 计算能力 (Compute Capability)

* **定义**：计算能力定义了 GPU 的特性和支持的功能（例如，支持的双精度浮点运算能力、最大共享内存大小、Warp 调度策略等）。
* **查询**：可以使用 CUDA API `cudaGetDeviceProperties` 来获取 GPU 的计算能力。
    ```c++
    cudaDeviceProp prop;
    cudaGetDeviceProperties(&prop, 0); // 获取设备0的属性
    printf("Compute Capability: %d.%d\n", prop.major, prop.minor);
    ```

#### 4.2.4 每个 SM 的寄存器和共享内存

* 每个 SM 都有固定的寄存器文件和共享内存容量。
* 这些资源由 SM 上并发执行的所有线程块共享。
* **影响占用率**：如果一个线程块需要大量寄存器或共享内存，那么同一个 SM 上可以并发执行的线程块数量就会减少，从而降低占用率。

#### 4.2.5 占用率 (Occupancy)

* **定义**：占用率是 GPU 上实际活跃 Warp 数量与理论上最大可能活跃 Warp 数量的比率。
    $$\text{Occupancy} = \frac{\text{Actual Active Warps}}{\text{Maximum Possible Active Warps}}$$
* **重要性**：
    * **隐藏延迟**：高占用率意味着 SM 有更多的活跃 Warp 可以切换，从而更好地隐藏内存访问和指令执行的延迟。当一个 Warp 等待数据时，SM 可以切换到另一个 Warp，保持计算单元繁忙。
    * **保持 SM 繁忙**：确保 SM 有足够的并行工作来保持其计算单元（ALU、LD/ST 单元）繁忙，从而提高整体 GPU 利用率。
* **影响因素**：
    * 每个线程的寄存器使用量。
    * 每个线程块的共享内存使用量。
    * 每个线程块的线程数。
    * SM 的资源限制（最大 Warp 数、最大寄存器数、最大共享内存）。
* **CUDA Occupancy Calculator**：这是一个 NVIDIA 提供的工具，可以帮助开发者根据上述参数预测占用率，并调整启动配置以优化性能。

**使用 CUDA Occupancy Calculator：**

1.  **输入参数**：
    * 目标 GPU 的计算能力。
    * 每个线程的寄存器使用量（通过 `nvcc -ptx` 或 `nvcc -cubin` 查看 `.reg` 指令）。
    * 每个线程块的共享内存使用量（通过 `__shared__` 声明）。
    * 每个线程块的线程数。
2.  **输出结果**：
    * 理论占用率。
    * 限制占用率的主要因素（是寄存器限制、共享内存限制还是每个 SM 的最大 Warp 限制）。

#### 4.2.6 实际占用率 vs. 理论占用率

* **理论占用率**：由 GPU 硬件资源限制和内核的资源需求计算出的最大可能占用率。
* **实际占用率**：内核实际运行时的平均占用率。
    * **通常**：理论占用率 $\geq$ 实际占用率。
    * **影响因素**：Warp 执行发散和块执行发散会导致实际占用率低于理论值。例如，某些 Warp 或块可能执行时间更长，导致其他 Warp 或块在等待。

#### 4.2.7 占用率与性能

* **并非越高越好**：达到最高性能不一定需要 100% 的占用率。
* **“所需”占用率**：存在一个“所需”占用率，一旦达到这个点，进一步提高占用率可能不会带来性能提升。
    * 这个“所需”占用率取决于代码的特性（例如，内存访问延迟、指令依赖等）。
    * **隐藏延迟示例**：
        * 如果全局内存访问需要 400 个周期，且每个周期可执行 2 条算术指令，则需要 200 条算术指令来隐藏延迟。
        * 假设代码中针对每个全局内存访问包含 8 条独立算术指令，那么需要 $200 / 8 = 25$ 个 Warp 来隐藏延迟（大约 52% 占用率，假设最大 Warp 数为 48）。超过这个占用率，性能可能不会再提升。
* **寄存器依赖导致的延迟隐藏**：
    * 如果一条指令用到寄存器中由上一条语句写入的结果，其延迟大约为 24 个周期。
    * 因此，需要 $24 / 2 = 12$ 个 Warp 来隐藏由于寄存器依赖引起的延迟（相应的占用率约为 25%）。

### 4.3 SM 如何隐藏延迟

* **多线程并发 (Multithreading)**：当一个 Warp 遇到长延迟操作（如全局内存访问或同步指令）时，它会暂停执行。
* **上下文切换 (Context Switching)**：SM 会快速地调度另一个准备好执行的活跃 Warp。
* **持续繁忙**：一旦长延迟操作完成，暂停的 Warp 就可以恢复执行。通过快速的上下文切换，SM 可以保持其计算单元的持续繁忙，从而提高吞吐量和利用率。
* **延迟隐藏在线程块粒度**：这意味着 Warp 切换只发生在同一个线程块内的 Warp 之间。不同线程块之间的切换发生在 SM 级别，而 Warp 切换发生在块内部。